{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf35466",
   "metadata": {},
   "source": [
    "# Machine learning for text classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2096a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# importing a stylesheet library for visualisations from source[1] \n",
    "#plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-light.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ea81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#??CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c81fa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"fake reviews dataset.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78252322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating label                                               text  \\\n",
       "0     5.0    CG  Love this!  Well made, sturdy, and very comfor...   \n",
       "1     5.0    CG  love it, a great upgrade from the original.  I...   \n",
       "2     5.0    CG  This pillow saved my back. I love the look and...   \n",
       "3     1.0    CG  Missing information on how to use it, but it i...   \n",
       "4     5.0    CG  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "   label_encoded  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.rename(columns={\"text_\":\"text\"})\n",
    "dataframe = dataframe.drop([\"category\"], axis=1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(dataframe['label'])\n",
    "dataframe['label_encoded'] = encoder.transform(dataframe['label'])\n",
    "\n",
    "dataframe.head()\n",
    "#df.label = df.label.apply(lambda v: 0 if v == \"ham\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb938a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why to use train test split and stratify: https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=420, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d857fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000 # make the top list of words (common words)\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>' # OOV = Out of Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06197a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=Y_hzMnRXjhI&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=3\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(x_train) # only fit to training data\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "print(train_padded[0])\n",
    "print(train_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lstm = 20\n",
    "drop_lstm =0.2\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "model1.add(LSTM(n_lstm, dropout=drop_lstm, return_sequences=True))\n",
    "model1.add(LSTM(n_lstm, dropout=drop_lstm, return_sequences=True))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944136bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    #tf.keras.layers.GlobalAveragePooling1D(), \n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_padded, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1ac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4b677",
   "metadata": {},
   "source": [
    "## deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4d6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def naive(n, smoothing):\n",
    "    # https://kavita-ganesan.com/how-to-use-countvectorizer/\n",
    "    cv = CountVectorizer(ngram_range=(n,n), stop_words=\"english\", analyzer='char_wb') # ref scikit learn documentation\n",
    "    train_features = cv.fit_transform(x_train)\n",
    "    test_features = cv.transform(x_test)\n",
    "\n",
    "    NB = MultinomialNB(alpha=smoothing)\n",
    "    NB.fit(train_features, y_train)\n",
    "\n",
    "    #pred = NB.predict(test_features)\n",
    "    #score = metrics.accuracy_score(y_test, pred)\n",
    "    #print(score)\n",
    "    \n",
    "    ## return here instead \n",
    "    print(\"accuracy is: \", NB.score(test_features, y_test))\n",
    "\n",
    "    #cm = metrics.confusion_matrix(y_test, pred)\n",
    "    #print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ngrams = [1,2,3]\n",
    "laplaces = [0.1, 1, 10]\n",
    "#counts\n",
    "for i in ngrams:\n",
    "    for j in laplaces:\n",
    "        print(\"ngrams: {} | laplace value: {}.\".format(i, j))\n",
    "        naive(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eff641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do fake and real reviews have the same legnth and polarity distribtuin. check word counts for each \n",
    "#do +ve and -ve reviews have the same length and dist\n",
    "# wordclouds for fake and real "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
